{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['titanic', 'forest-cover-type-kernels-only']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from pyspark import SparkContext\nsc = SparkContext()\nfrom pyspark.sql import SparkSession\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.mllib.regression import LinearRegressionWithSGD as lrSGD\nfrom pyspark.sql import functions as F\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7425d674cbe6c1277313785cf306e500b043657"},"cell_type":"code","source":"spark = SparkSession \\\n   .builder \\\n   .appName(\"Titanic PySpark Exercise\") \\\n   .config(\"spark.some.config.option\", \"some-value\") \\\n   .getOrCreate()","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Learning Objectives\n\n- Learn all of the methods in pandas for data-frame manipulation\n- The dataset we use is Titanic dataset\n- Apply visualization to data-frame"},{"metadata":{},"cell_type":"markdown","source":"### Lets make Pandas dataframe from titanic csv file "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = spark.read.csv('../input/titanic/train.csv', header = True)","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets look at the first 5 rows of dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.show(5)","execution_count":5,"outputs":[{"output_type":"stream","text":"+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex|Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n|          1|       0|     3|Braund, Mr. Owen ...|  male| 22|    1|    0|       A/5 21171|   7.25| null|       S|\n|          2|       1|     1|Cumings, Mrs. Joh...|female| 38|    1|    0|        PC 17599|71.2833|  C85|       C|\n|          3|       1|     3|Heikkinen, Miss. ...|female| 26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n|          4|       1|     1|Futrelle, Mrs. Ja...|female| 35|    1|    0|          113803|   53.1| C123|       S|\n|          5|       0|     3|Allen, Mr. Willia...|  male| 35|    0|    0|          373450|   8.05| null|       S|\n+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\nonly showing top 5 rows\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.count(), len(df.columns)","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"(891, 12)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Titanic Dataset Description"},{"metadata":{"trusted":true},"cell_type":"code","source":"# VARIABLE DESCRIPTIONS:\n# survival        Survival\n#                 (0 = No; 1 = Yes)\n# pclass          Passenger Class\n#                 (1 = 1st; 2 = 2nd; 3 = 3rd)\n# name            Name\n# sex             Sex\n# age             Age\n# sibsp           Number of Siblings/Spouses Aboard\n# parch           Number of Parents/Children Aboard\n# ticket          Ticket Number\n# fare            Passenger Fare\n# cabin           Cabin\n# embarked        Port of Embarkation\n#                 (C = Cherbourg; Q = Queenstown; S = Southampton)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO\n\n# import matplotlib.pyplot as plt\n\n# df_pandas = df.toPandas() \n\n# df_pandas['Age'].hist(bins=16)\n# plt.show()","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How many of Age values are empty (or null)?"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark.sql.functions import isnan, when, count, col\n\ndf.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n","execution_count":9,"outputs":[{"output_type":"stream","text":"+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n|          0|       0|     0|   0|  0|177|    0|    0|     0|   0|  687|       2|\n+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Create a new column as gender, when Sex is female it is zero when sex is male it is one\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.withColumn(\"Gender\", when(df['Sex'] == \"female\", 0).otherwise(1))\ndf.show()","execution_count":10,"outputs":[{"output_type":"stream","text":"+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Gender|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n|          1|       0|     3|Braund, Mr. Owen ...|  male|  22|    1|    0|       A/5 21171|   7.25| null|       S|     1|\n|          2|       1|     1|Cumings, Mrs. Joh...|female|  38|    1|    0|        PC 17599|71.2833|  C85|       C|     0|\n|          3|       1|     3|Heikkinen, Miss. ...|female|  26|    0|    0|STON/O2. 3101282|  7.925| null|       S|     0|\n|          4|       1|     1|Futrelle, Mrs. Ja...|female|  35|    1|    0|          113803|   53.1| C123|       S|     0|\n|          5|       0|     3|Allen, Mr. Willia...|  male|  35|    0|    0|          373450|   8.05| null|       S|     1|\n|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|     1|\n|          7|       0|     1|McCarthy, Mr. Tim...|  male|  54|    0|    0|           17463|51.8625|  E46|       S|     1|\n|          8|       0|     3|Palsson, Master. ...|  male|   2|    3|    1|          349909| 21.075| null|       S|     1|\n|          9|       1|     3|Johnson, Mrs. Osc...|female|  27|    0|    2|          347742|11.1333| null|       S|     0|\n|         10|       1|     2|Nasser, Mrs. Nich...|female|  14|    1|    0|          237736|30.0708| null|       C|     0|\n|         11|       1|     3|Sandstrom, Miss. ...|female|   4|    1|    1|         PP 9549|   16.7|   G6|       S|     0|\n|         12|       1|     1|Bonnell, Miss. El...|female|  58|    0|    0|          113783|  26.55| C103|       S|     0|\n|         13|       0|     3|Saundercock, Mr. ...|  male|  20|    0|    0|       A/5. 2151|   8.05| null|       S|     1|\n|         14|       0|     3|Andersson, Mr. An...|  male|  39|    1|    5|          347082| 31.275| null|       S|     1|\n|         15|       0|     3|Vestrom, Miss. Hu...|female|  14|    0|    0|          350406| 7.8542| null|       S|     0|\n|         16|       1|     2|Hewlett, Mrs. (Ma...|female|  55|    0|    0|          248706|     16| null|       S|     0|\n|         17|       0|     3|Rice, Master. Eugene|  male|   2|    4|    1|          382652| 29.125| null|       Q|     1|\n|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|     13| null|       S|     1|\n|         19|       0|     3|Vander Planke, Mr...|female|  31|    1|    0|          345763|     18| null|       S|     0|\n|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|     0|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\nonly showing top 20 rows\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### We have one more column (check it)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.count(), len(df.columns)","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"(891, 13)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Show the majority of Age range"},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### List all of the Ages that are not null"},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO\n# df.select(df['Age'].isNotNull()).show()\n\n\n# df.filter(df['Age'].isNotNull()).show()\n\n# df.select([column for column in df['Age'] if df.select(column).isNotNull()]).show()\n\n\n# df.select(df['Age'], F.when(df['Age'] == df['Age'].isNotNull(), None)).show()\n# df.where(col(\"Age\").isNotNull()).show()\n\n\n# select(\n#      coalesce(df_a(\"mobile1\"), df_b(\"mobile2\"), lit(0))\n\n# >>> from pyspark.sql import functions as F\n# >>> df.select(df.name, F.when(df.age > 3, 1).otherwise(0)).show()\n\n# from pyspark.sql.functions import array_contains\n# df.select(df['Age'], [(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).collect()\n# df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n\n# df.select(array_contains(df.Age, isnull())).collect()\n\n# df.filter(df['Age'] != df['Age'].isNull()).show()\n\n\n# df.groupBy('Age') \\\n#     .agg((F.count(F.col(\"Sales\").isNotNull()).alias(\"sales_count\"))).show()\nfor column in df['Age']:\n    print(column)\n","execution_count":55,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"Column is not iterable","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-d1c05199c076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# df.groupBy('Age') \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#     .agg((F.count(F.col(\"Sales\").isNotNull()).alias(\"sales_count\"))).show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pyspark/sql/column.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Column is not iterable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;31m# string methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Column is not iterable"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Slice the dataframe for those whose Embarked section was 'C'"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.filter(df['Embarked'] == \"C\").show()","execution_count":14,"outputs":[{"output_type":"stream","text":"+-----------+--------+------+--------------------+------+----+-----+-----+-------------+--------+-----+--------+------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|       Ticket|    Fare|Cabin|Embarked|Gender|\n+-----------+--------+------+--------------------+------+----+-----+-----+-------------+--------+-----+--------+------+\n|          2|       1|     1|Cumings, Mrs. Joh...|female|  38|    1|    0|     PC 17599| 71.2833|  C85|       C|     0|\n|         10|       1|     2|Nasser, Mrs. Nich...|female|  14|    1|    0|       237736| 30.0708| null|       C|     0|\n|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|         2649|   7.225| null|       C|     0|\n|         27|       0|     3|Emir, Mr. Farred ...|  male|null|    0|    0|         2631|   7.225| null|       C|     1|\n|         31|       0|     1|Uruchurtu, Don. M...|  male|  40|    0|    0|     PC 17601| 27.7208| null|       C|     1|\n|         32|       1|     1|Spencer, Mrs. Wil...|female|null|    1|    0|     PC 17569|146.5208|  B78|       C|     0|\n|         35|       0|     1|Meyer, Mr. Edgar ...|  male|  28|    1|    0|     PC 17604| 82.1708| null|       C|     1|\n|         37|       1|     3|    Mamee, Mr. Hanna|  male|null|    0|    0|         2677|  7.2292| null|       C|     1|\n|         40|       1|     3|Nicola-Yarred, Mi...|female|  14|    1|    0|         2651| 11.2417| null|       C|     0|\n|         43|       0|     3| Kraeff, Mr. Theodor|  male|null|    0|    0|       349253|  7.8958| null|       C|     1|\n|         44|       1|     2|Laroche, Miss. Si...|female|   3|    1|    2|SC/Paris 2123| 41.5792| null|       C|     0|\n|         49|       0|     3| Samaan, Mr. Youssef|  male|null|    2|    0|         2662| 21.6792| null|       C|     1|\n|         53|       1|     1|Harper, Mrs. Henr...|female|  49|    1|    0|     PC 17572| 76.7292|  D33|       C|     0|\n|         55|       0|     1|Ostby, Mr. Engelh...|  male|  65|    0|    1|       113509| 61.9792|  B30|       C|     1|\n|         58|       0|     3| Novel, Mr. Mansouer|  male|28.5|    0|    0|         2697|  7.2292| null|       C|     1|\n|         61|       0|     3|Sirayanian, Mr. O...|  male|  22|    0|    0|         2669|  7.2292| null|       C|     1|\n|         65|       0|     1|Stewart, Mr. Albe...|  male|null|    0|    0|     PC 17605| 27.7208| null|       C|     1|\n|         66|       1|     3|Moubarek, Master....|  male|null|    1|    1|         2661| 15.2458| null|       C|     1|\n|         74|       0|     3|Chronopoulos, Mr....|  male|  26|    1|    0|         2680| 14.4542| null|       C|     1|\n|         97|       0|     1|Goldschmidt, Mr. ...|  male|  71|    0|    0|     PC 17754| 34.6542|   A5|       C|     1|\n+-----------+--------+------+--------------------+------+----+-----+-----+-------------+--------+-----+--------+------+\nonly showing top 20 rows\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Plot the Age range for those whose Embraked were 'C'"},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Apply couple of Normal Distributions to Histogram obtained above "},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Describe a specific column "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(['Embarked']).show()","execution_count":17,"outputs":[{"output_type":"stream","text":"+-------+--------+\n|summary|Embarked|\n+-------+--------+\n|  count|     889|\n|   mean|    null|\n| stddev|    null|\n|    min|       C|\n|    max|       S|\n+-------+--------+\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### How many unique values does the 'Embraked' have?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.select('Embarked').distinct().dropna().count()","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"3"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Count the different 'Embarked' values the dataframe has"},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Count the different 'Embarked' values the dataframe has and plot horizontaly"},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO","execution_count":20,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Another way to do the count and plot it"},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.select('Embarked').distinct().count()\n\ndf.groupBy(\"Embarked\").count().dropna().show()\n# .count().orderBy().show()","execution_count":33,"outputs":[{"output_type":"stream","text":"+--------+-----+\n|Embarked|count|\n+--------+-----+\n|       Q|   77|\n|       C|  168|\n|       S|  644|\n+--------+-----+\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupBy(\"Sex\").count().toJSON().collect()","execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"['{\"Sex\":\"female\",\"count\":314}', '{\"Sex\":\"male\",\"count\":577}']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO\n# df['Sex'].value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot how many of the passengers were children, youth, middle age and old based on there Sex for those who 'Embarked' in section 'C'?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in df[df['Embarked'] == 'C'].groupby('Sex')['Age']:\n#     print(i)\ndf.groupBy(\"Embarked\").agg(df['Embarked'] == 'C').count()","execution_count":68,"outputs":[{"output_type":"execute_result","execution_count":68,"data":{"text/plain":"4"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO\n# df[df['Embarked'] == 'C'].groupby('Sex')['Age'].hist(bins=16, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO\n# df[df['Embarked'] == 'C'].groupby('Sex')['Age'].plot(bins=16, kind='hist', legend=True, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df[df['Embarked'] == 'C'].groupby('Sex')['Age'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64aeb79ffd1b788334a122538fe61aa672760238"},"cell_type":"code","source":"spark = SparkSession.Builder().getOrCreate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1714177e3b9452e85741c25d7e078bbcdbbb4e2f"},"cell_type":"code","source":"from pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38504481d3a6f24df439ed1c5bbc55799a9796db"},"cell_type":"code","source":"train = spark.read.csv('../input/train.csv',header = True,inferSchema=True)\ntest = spark.read.csv('../input/test.csv',header = True,inferSchema=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef21c54b712aac88774308cc98cd65ce158a2641"},"cell_type":"code","source":"train.limit(5).toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80f168a59f5ff594bed363a466278e5140ed9e7c"},"cell_type":"code","source":"test.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e8a3204155d3837cc7818510d79ff967252ea6d"},"cell_type":"code","source":"train_mod = train.withColumn(\"HF1\", train.Horizontal_Distance_To_Hydrology + train.Horizontal_Distance_To_Fire_Points) \\\n.withColumn(\"HF2\", abs(train.Horizontal_Distance_To_Hydrology - train.Horizontal_Distance_To_Fire_Points)) \\\n.withColumn(\"HR1\", abs(train.Horizontal_Distance_To_Hydrology + train.Horizontal_Distance_To_Roadways)) \\\n.withColumn(\"HR2\", abs(train.Horizontal_Distance_To_Hydrology - train.Horizontal_Distance_To_Roadways)) \\\n.withColumn(\"FR1\", abs(train.Horizontal_Distance_To_Fire_Points + train.Horizontal_Distance_To_Roadways)) \\\n.withColumn(\"FR2\", abs(train.Horizontal_Distance_To_Fire_Points - train.Horizontal_Distance_To_Roadways)) \\\n.withColumn(\"ele_vert\", train.Elevation - train.Vertical_Distance_To_Hydrology) \\\n.withColumn(\"slope_hyd\", pow((pow(train.Horizontal_Distance_To_Hydrology,2) + pow(train.Vertical_Distance_To_Hydrology,2)),0.5)) \\\n.withColumn(\"Mean_Amenities\", (train.Horizontal_Distance_To_Fire_Points + train.Horizontal_Distance_To_Hydrology + train.Horizontal_Distance_To_Roadways)/3) \\\n.withColumn(\"Mean_Fire_Hyd\", (train.Horizontal_Distance_To_Fire_Points + train.Horizontal_Distance_To_Hydrology)/2)\n\ntest_mod = test.withColumn(\"HF1\", test.Horizontal_Distance_To_Hydrology + test.Horizontal_Distance_To_Fire_Points) \\\n.withColumn(\"HF2\", abs(test.Horizontal_Distance_To_Hydrology - test.Horizontal_Distance_To_Fire_Points)) \\\n.withColumn(\"HR1\", abs(test.Horizontal_Distance_To_Hydrology + test.Horizontal_Distance_To_Roadways)) \\\n.withColumn(\"HR2\", abs(test.Horizontal_Distance_To_Hydrology - test.Horizontal_Distance_To_Roadways)) \\\n.withColumn(\"FR1\", abs(test.Horizontal_Distance_To_Fire_Points + test.Horizontal_Distance_To_Roadways)) \\\n.withColumn(\"FR2\", abs(test.Horizontal_Distance_To_Fire_Points - test.Horizontal_Distance_To_Roadways)) \\\n.withColumn(\"ele_vert\", test.Elevation - test.Vertical_Distance_To_Hydrology) \\\n.withColumn(\"slope_hyd\", pow((pow(test.Horizontal_Distance_To_Hydrology,2) + pow(test.Vertical_Distance_To_Hydrology,2)),0.5)) \\\n.withColumn(\"Mean_Amenities\", (test.Horizontal_Distance_To_Fire_Points + test.Horizontal_Distance_To_Hydrology + test.Horizontal_Distance_To_Roadways)/3) \\\n.withColumn(\"Mean_Fire_Hyd\", (test.Horizontal_Distance_To_Fire_Points + test.Horizontal_Distance_To_Hydrology)/2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"907b49915faea706ece65e022a827cc30f30368d"},"cell_type":"code","source":"train_mod.limit(2).toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f517ebbf034e3b94ff3f6739b7108d3a089a45b5"},"cell_type":"code","source":"test_mod.limit(2).toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37489962d27a8f2ea523732f0422b96b7b8910e7"},"cell_type":"code","source":"test_mod.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2649a43f9dcaf65ffd8c62d5cb6ad663b17c3a0a"},"cell_type":"code","source":"train_columns = test_mod.columns[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a162bf4d0c104bdeaf0b11b65378e93900f7e609"},"cell_type":"code","source":"train_mod.printSchema","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"192d5d6ddaf72b556d1e0340598072ac7234018b"},"cell_type":"code","source":"from pyspark.ml.feature import VectorAssembler\nassembler = VectorAssembler()\\\n.setInputCols(train_columns)\\\n.setOutputCol(\"features\")\ntrain_mod01 = assembler.transform(train_mod)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a907f3f59b0745e32338c9f647b151b0b82f1758"},"cell_type":"code","source":"train_mod01.limit(2).toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e5b2a0b0530e43525b7c64b58d37b02175f8de2"},"cell_type":"code","source":"train_mod02 = train_mod01.select(\"features\",\"Cover_Type\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41090f3baf51723dff3b54439db07f03927ff61f"},"cell_type":"code","source":"test_mod01 = assembler.transform(test_mod)\ntest_mod02 = test_mod01.select(\"Id\",\"features\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c3d8ef192cdeee39e3faebef5ba3c7d584bacd6"},"cell_type":"code","source":"from pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel\nrfClassifer = RandomForestClassifier(labelCol = \"Cover_Type\", numTrees = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a04310219c325eb32b7818ba021260d0a0ae594"},"cell_type":"code","source":"from pyspark.ml import Pipeline\npipeline = Pipeline(stages = [rfClassifer])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"445022a3c384ad4b087728dad396cc202555f1ef"},"cell_type":"code","source":"from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b38cf4cbdb5f4ae55528ecc3f5b9878969215038"},"cell_type":"code","source":"paramGrid = ParamGridBuilder()\\\n   .addGrid(rfClassifer.maxDepth, [1, 2, 4, 5, 6, 7, 8])\\\n   .addGrid(rfClassifer.minInstancesPerNode, [1, 2, 4, 5, 6, 7, 8])\\\n   .build()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a66fe6c0fd25ff90f70af6291071f299526f78f"},"cell_type":"code","source":"evaluator = MulticlassClassificationEvaluator(labelCol = \"Cover_Type\", predictionCol = \"prediction\", metricName = \"accuracy\") \n\ncrossval = CrossValidator(estimator = pipeline,\n                          estimatorParamMaps = paramGrid,\n                          evaluator = evaluator,\n                          numFolds = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ccead2ab36674d1b2e2b00d289379801acdf6f4"},"cell_type":"code","source":"cvModel = crossval.fit(train_mod02)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7904aad9bfb29d10979fb6cb3914666f1ecc4b00"},"cell_type":"code","source":"cvModel.avgMetrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbe6dac26df3b08ef4c2ba8c3e1557c3e1d69c0b"},"cell_type":"code","source":"cvModel.bestModel.stages","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5ad695c85992d228d2568b8917580f0185f1db1"},"cell_type":"code","source":"prediction = cvModel.transform(test_mod02)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbff344e959a0f909104fedfe1497ab68bf6451b"},"cell_type":"code","source":"selected = prediction.select(\"Id\",\"features\", \"probability\", \"prediction\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9eba519f9cdcfe930d6d73a01d1ff1f6da0ddb9"},"cell_type":"code","source":"selected.limit(5).toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c1b584c41ebef917b97f92ea1821801996e5255"},"cell_type":"code","source":"sub_final = selected.select(col(\"Id\"),col(\"prediction\").cast(IntegerType()).alias(\"Cover_Type\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39d0a69d30a99fcefd94842b6ddc661c75d71813"},"cell_type":"code","source":"sub_final.limit(2).toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ef873258d82bfbfea24dda9e78639d222282603"},"cell_type":"code","source":"sub_final.toPandas().to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}